*Vocab*
Agent:              Anything that perceives its environment through sensors and acts on the environment through actuators.
Percept sequence:   A complete history of everything the agent has ever perceived. 
Agent function:     Maps precept sequence to action.
Agent program:      Implements the agent function.
Rationality:        Do the actions that cause the agent to be most successful.
    1) Performance measure of success
    2) Agents's prior knowledge of environment
    3) Actions agent can perform
    4) Agents's percept sequence to date

*Learning*
1) Initially, designers compute some prior knowledge to include in policy.
2) When deciding its next action, agent does some computation

Performance, Environment, Actuators, Sensors (PEAS Descriptions of Task environments)


*Properties of Onvironmonts*
Fully Observable: Can access complete state of environment at each point in time.
    - Partially observable: Could be due to noisy, inaccurate sensor data
Deterministic: If next state of the environment completely determined by current state and agent's action
    - Stochastic: A partially observable environment can appear to be stochastic. 
    - Strategic:  Environment is deterministic except for actions of other agents.
Episodic: Agent's experience divided into independent' atomic episodes in which agents perceives and performs a single action in each episode.
    - Sequential: Current decision affects all future decisions.
Static: Agent doesn't need to keep sensing while decides what action to take, doesn't need to worry about time.
    - Dynamic: Environment changes while agent is thinking.
    - Semidynamic: environment doesn't change with time but agent's performance does
Discrete: 
